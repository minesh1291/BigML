{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME=\"my-kaggle-competitions\"\n",
    "myBucket=\"gs://mkc_transfer/myWorkspace/bigML\"\n",
    "cluster_name=\"cluster-5488\"\n",
    "cluster_region=\"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://natality_sparkml.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  2.5 KiB/  2.5 KiB]                                                \n",
      "Operation completed over 1 objects/2.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp natality_sparkml.py $myBucket/natality/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mkc_transfer/myWorkspace/bigML/natality/natality_sparkml.py\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $myBucket/natality/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30.93 MiB  2020-04-27T17:12:34Z  gs://spark-lib/bigquery/spark-bigquery-latest.jar\n",
      "TOTAL: 1 objects, 32436661 bytes (30.93 MiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -lh gs://spark-lib/bigquery/spark-bigquery-latest.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [ad1b3ae44d124012ba2f1d22564c4f0b] submitted.\n",
      "Waiting for job output...\n",
      "20/06/08 22:47:09 INFO org.spark_project.jetty.util.log: Logging initialized @4244ms\n",
      "20/06/08 22:47:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\n",
      "20/06/08 22:47:09 INFO org.spark_project.jetty.server.Server: Started @4336ms\n",
      "20/06/08 22:47:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@111afbd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
      "20/06/08 22:47:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.\n",
      "20/06/08 22:47:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at cluster-5488-m/10.128.0.25:8032\n",
      "20/06/08 22:47:11 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at cluster-5488-m/10.128.0.25:10200\n",
      "20/06/08 22:47:14 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1591656376995_0001\n",
      "20/06/08 22:47:24 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Querying table my-kaggle-competitions.natality_regression.regression_input, parameters sent from Spark: requiredColumns=[weight_pounds,mother_age,father_age,gestation_weeks,weight_gain_pounds,apgar_5min], filters=[IsNotNull(weight_pounds),IsNotNull(mother_age),IsNotNull(father_age),IsNotNull(gestation_weeks)]\n",
      "20/06/08 22:47:24 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Going to read from my-kaggle-competitions.natality_regression.regression_input columns=[weight_pounds, mother_age, father_age, gestation_weeks, weight_gain_pounds, apgar_5min], filter='(`father_age` IS NOT NULL AND `gestation_weeks` IS NOT NULL AND `mother_age` IS NOT NULL AND `weight_pounds` IS NOT NULL)'\n",
      "20/06/08 22:47:26 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Created read session for table 'my-kaggle-competitions.natality_regression.regression_input': projects/my-kaggle-competitions/locations/us/sessions/CAISDENIYnQ2Nm9kV3c4QxoCamQaAml3GgJuYRoCb3MaAmluGgJqcRoCanIaAmlyGgJqYxoCb2o\n",
      "20/06/08 22:47:26 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Requested 9 max partitions, but only received 4 from the BigQuery Storage API for session projects/my-kaggle-competitions/locations/us/sessions/CAISDENIYnQ2Nm9kV3c4QxoCamQaAml3GgJuYRoCb3MaAmluGgJqcRoCanIaAmlyGgJqYxoCb2o. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
      "20/06/08 23:02:07 INFO com.github.fommil.jni.JniLoader: successfully loaded /tmp/jniloader6097563781580007826netlib-native_system-linux-x86_64.so\n",
      "20/06/08 23:14:35 INFO com.github.fommil.jni.JniLoader: already loaded netlib-native_system-linux-x86_64.so\n",
      "Coefficients:[0.01666574544477423,-0.0029675198430991687,0.23571439262198124,0.002130020703155612,-0.00048577251995183765]\n",
      "Intercept:-2.26130329478\n",
      "R^2:0.295200578949\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  0.6197967670040523|\n",
      "| -0.9671612706158506|\n",
      "|  -1.806433827795824|\n",
      "| -2.1381180135820417|\n",
      "|  1.6898190538295896|\n",
      "|  0.9109068491142978|\n",
      "| -0.5958576635747708|\n",
      "| -0.4719903744153022|\n",
      "| -0.5736943696214372|\n",
      "|-0.10143354653728487|\n",
      "|   0.404388509206564|\n",
      "|  2.2099306165439145|\n",
      "| -1.0674968314623987|\n",
      "| 0.25462660127661785|\n",
      "|-0.02770831944092...|\n",
      "| -0.8906268259902346|\n",
      "|  -0.555015829338747|\n",
      "| -0.5477303998430516|\n",
      "| -0.7157399935566424|\n",
      "| -0.7009808587859085|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "20/06/08 23:15:26 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@111afbd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
      "Job [ad1b3ae44d124012ba2f1d22564c4f0b] finished successfully.\n",
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-986649903191-tqtqa1dv/google-cloud-dataproc-metainfo/466e702d-2768-485c-b457-37fff9609dc3/jobs/ad1b3ae44d124012ba2f1d22564c4f0b/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-986649903191-tqtqa1dv/google-cloud-dataproc-metainfo/466e702d-2768-485c-b457-37fff9609dc3/jobs/ad1b3ae44d124012ba2f1d22564c4f0b/driveroutput\n",
      "jobUuid: f7e0e6eb-9769-36aa-a8f7-c759b9f21fc7\n",
      "placement:\n",
      "  clusterName: cluster-5488\n",
      "  clusterUuid: 466e702d-2768-485c-b457-37fff9609dc3\n",
      "pysparkJob:\n",
      "  fileUris:\n",
      "  - gs://mkc_transfer/myWorkspace/bigML/natality/natality_sparkml.py\n",
      "  jarFileUris:\n",
      "  - gs://spark-lib/bigquery/spark-bigquery-latest.jar\n",
      "  mainPythonFileUri: gs://mkc_transfer/myWorkspace/bigML/natality/natality_sparkml.py\n",
      "reference:\n",
      "  jobId: ad1b3ae44d124012ba2f1d22564c4f0b\n",
      "  projectId: my-kaggle-competitions\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2020-06-08T23:15:28.028Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2020-06-08T22:45:30.211Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2020-06-08T22:45:30.266Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2020-06-08T22:45:30.366Z'\n",
      "yarnApplications:\n",
      "- name: natality_sparkml.py\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://cluster-5488-m:8088/proxy/application_1591656376995_0001/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit pyspark $myBucket/natality/natality_sparkml.py \\\n",
    "    --cluster=$cluster_name \\\n",
    "    --region=$cluster_region \\\n",
    "    --files=$myBucket/natality/natality_sparkml.py \\\n",
    "    --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Job [ad1b3ae44d124012ba2f1d22564c4f0b] submitted.\n",
    "# Waiting for job output...\n",
    "# 20/06/08 22:47:09 INFO org.spark_project.jetty.util.log: Logging initialized @4244ms\n",
    "# 20/06/08 22:47:09 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown\n",
    "# 20/06/08 22:47:09 INFO org.spark_project.jetty.server.Server: Started @4336ms\n",
    "# 20/06/08 22:47:09 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@111afbd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
    "# 20/06/08 22:47:09 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.\n",
    "# 20/06/08 22:47:10 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at cluster-5488-m/10.128.0.25:8032\n",
    "# 20/06/08 22:47:11 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at cluster-5488-m/10.128.0.25:10200\n",
    "# 20/06/08 22:47:14 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1591656376995_0001\n",
    "# 20/06/08 22:47:24 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Querying table my-kaggle-competitions.natality_regression.regression_input, parameters sent from Spark: requiredColumns=[weight_pounds,mother_age,father_age,gestation_weeks,weight_gain_pounds,apgar_5min], filters=[IsNotNull(weight_pounds),IsNotNull(mother_age),IsNotNull(father_age),IsNotNull(gestation_weeks)]\n",
    "# 20/06/08 22:47:24 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Going to read from my-kaggle-competitions.natality_regression.regression_input columns=[weight_pounds, mother_age, father_age, gestation_weeks, weight_gain_pounds, apgar_5min], filter='(`father_age` IS NOT NULL AND `gestation_weeks` IS NOT NULL AND `mother_age` IS NOT NULL AND `weight_pounds` IS NOT NULL)'\n",
    "# 20/06/08 22:47:26 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Created read session for table 'my-kaggle-competitions.natality_regression.regression_input': projects/my-kaggle-competitions/locations/us/sessions/CAISDENIYnQ2Nm9kV3c4QxoCamQaAml3GgJuYRoCb3MaAmluGgJqcRoCanIaAmlyGgJqYxoCb2o\n",
    "# 20/06/08 22:47:26 INFO com.google.cloud.spark.bigquery.direct.DirectBigQueryRelation: Requested 9 max partitions, but only received 4 from the BigQuery Storage API for session projects/my-kaggle-competitions/locations/us/sessions/CAISDENIYnQ2Nm9kV3c4QxoCamQaAml3GgJuYRoCb3MaAmluGgJqcRoCanIaAmlyGgJqYxoCb2o. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
    "# 20/06/08 23:02:07 INFO com.github.fommil.jni.JniLoader: successfully loaded /tmp/jniloader6097563781580007826netlib-native_system-linux-x86_64.so\n",
    "# 20/06/08 23:14:35 INFO com.github.fommil.jni.JniLoader: already loaded netlib-native_system-linux-x86_64.so\n",
    "# Coefficients:[0.01666574544477423,-0.0029675198430991687,0.23571439262198124,0.002130020703155612,-0.00048577251995183765]\n",
    "# Intercept:-2.26130329478\n",
    "# R^2:0.295200578949\n",
    "# +--------------------+\n",
    "# |           residuals|\n",
    "# +--------------------+\n",
    "# |  0.6197967670040523|\n",
    "# | -0.9671612706158506|\n",
    "# |  -1.806433827795824|\n",
    "# | -2.1381180135820417|\n",
    "# |  1.6898190538295896|\n",
    "# |  0.9109068491142978|\n",
    "# | -0.5958576635747708|\n",
    "# | -0.4719903744153022|\n",
    "# | -0.5736943696214372|\n",
    "# |-0.10143354653728487|\n",
    "# |   0.404388509206564|\n",
    "# |  2.2099306165439145|\n",
    "# | -1.0674968314623987|\n",
    "# | 0.25462660127661785|\n",
    "# |-0.02770831944092...|\n",
    "# | -0.8906268259902346|\n",
    "# |  -0.555015829338747|\n",
    "# | -0.5477303998430516|\n",
    "# | -0.7157399935566424|\n",
    "# | -0.7009808587859085|\n",
    "# +--------------------+\n",
    "# only showing top 20 rows\n",
    "\n",
    "# 20/06/08 23:15:26 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@111afbd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
    "# Job [ad1b3ae44d124012ba2f1d22564c4f0b] finished successfully.\n",
    "# done: true\n",
    "# driverControlFilesUri: gs://dataproc-staging-us-central1-986649903191-tqtqa1dv/google-cloud-dataproc-metainfo/466e702d-2768-485c-b457-37fff9609dc3/jobs/ad1b3ae44d124012ba2f1d22564c4f0b/\n",
    "# driverOutputResourceUri: gs://dataproc-staging-us-central1-986649903191-tqtqa1dv/google-cloud-dataproc-metainfo/466e702d-2768-485c-b457-37fff9609dc3/jobs/ad1b3ae44d124012ba2f1d22564c4f0b/driveroutput\n",
    "# jobUuid: f7e0e6eb-9769-36aa-a8f7-c759b9f21fc7\n",
    "# placement:\n",
    "#   clusterName: cluster-5488\n",
    "#   clusterUuid: 466e702d-2768-485c-b457-37fff9609dc3\n",
    "# pysparkJob:\n",
    "#   fileUris:\n",
    "#   - gs://mkc_transfer/myWorkspace/bigML/natality/natality_sparkml.py\n",
    "#   jarFileUris:\n",
    "#   - gs://spark-lib/bigquery/spark-bigquery-latest.jar\n",
    "#   mainPythonFileUri: gs://mkc_transfer/myWorkspace/bigML/natality/natality_sparkml.py\n",
    "# reference:\n",
    "#   jobId: ad1b3ae44d124012ba2f1d22564c4f0b\n",
    "#   projectId: my-kaggle-competitions\n",
    "# status:\n",
    "#   state: DONE\n",
    "#   stateStartTime: '2020-06-08T23:15:28.028Z'\n",
    "# statusHistory:\n",
    "# - state: PENDING\n",
    "#   stateStartTime: '2020-06-08T22:45:30.211Z'\n",
    "# - state: SETUP_DONE\n",
    "#   stateStartTime: '2020-06-08T22:45:30.266Z'\n",
    "# - details: Agent reported job success\n",
    "#   state: RUNNING\n",
    "#   stateStartTime: '2020-06-08T22:45:30.366Z'\n",
    "# yarnApplications:\n",
    "# - name: natality_sparkml.py\n",
    "#   progress: 1.0\n",
    "#   state: FINISHED\n",
    "#   trackingUrl: http://cluster-5488-m:8088/proxy/application_1591656376995_0001/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
